{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset Research**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Identifying and Defining**\n",
    "### **The Scenario and Purpose:**\n",
    "**Data:** My chosen scenario includes a comprehensive list of Hollywood movies with the highest box office gross in the world. This is based on many different factors, such as the movie name, budget, distributor, worldwide sales, genre and release date. \n",
    "\n",
    "**Goal:** My goal is to attempt, discover and learn the top 1000 highest-grossing Hollywood movies of all time, with the help of the dataset.\n",
    "\n",
    "**Access:** The dataset is published onto Kaggle with a public status, meaning anyone can view, discuss and download it.\n",
    "\n",
    "**Access Method:** The dataset can be downloaded on Kaggle as a CSV file, and will be analyzed in the CSV file format.\n",
    "\n",
    "**Source:** https://www.kaggle.com/datasets/sanjeetsinghnaik/top-1000-highest-grossing-movies/data\n",
    "### **Functional Requirements**\n",
    "#### **Data Loading**\n",
    "In terms of data loading, the dataset must be suitable for analysis. The dataset must be downloaded or converted into an appropriate file format for use, such as the CSV file format, as the CSV file format is typically the best to perform data analysis procedures in.\n",
    "* **Input:** The user will need to input an appropriate file format such as .CSV\n",
    "* **Output:** There wouldn't be an output.\n",
    "#### **Data Cleaning**\n",
    "In terms of data cleaning, the system will need to be able to fix or remove incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within the dataset. In terms of achieving this, the system will need to be able to identify data discrepancies using data observability tools, remove unnecessary values and duplicate data, fix structural errors, address any missing values, standardize data entry and formatting, and develop a data quality strategy.\n",
    "* **Input:** The user will need to filter data using either Pandas or Microsoft Excel.\n",
    "* **Output:** If done correctly, a neat and processed dataset should be outputted by the program used.\n",
    "#### **Data Analysis**\n",
    "In terms of data analysis, the statistical analysis will need to be able to obtain raw data and subsequently convert it into information useful for decision-making by users. Data will collected and analyzed to answer questions, test hypotheses, or disprove theories.\n",
    "* **Input:** The user will need to run a program capable of processing and analyzing data accurately.\n",
    "* **Output:** If done correctly, the used program will output the necessary analysis results requested by the user.\n",
    "#### **Data Visualization**\n",
    "In terms of data visualization, the data from the dataset will need to be represented visually through use of common graphics, such as charts, plots, infographics and even animations.\n",
    "* **Input:** The user will first need to determine what type of graphics they want to visualize the data in, then they will need to specify the type of graphics through the Matplotlib module.\n",
    "* **Output:** The system will need to output the specified graphics requested by the user. The graphics outputted must be able to present the data correctly and easily.\n",
    "#### **Data Reporting**\n",
    "In terms of data reporting, the system will need to collect unprocessed data from different sources that can later be organized into meaningful pieces of information. These pieces of information can give valuable insights and statistics about the topic of the collected data.\n",
    "* **Input:** The user will need to request statistical information from the program.\n",
    "* **Output:** The system will need to output the statistical information the user requested in a fully valid form with zero errors.\n",
    "### **Use Cases**\n",
    "#### **Data Loading**\n",
    "**Actor:** Data Analyst\n",
    "\n",
    "**Goal:** To import the correct file format as a dataset into the system.\n",
    "\n",
    "**Preconditions:** User has a dataset ready to be imported.\n",
    "> Step 1: User organizes the files and places the dataset into the appropriate folder to be read.\n",
    ">\n",
    "> Step 2: System scans and reads through the dataset, then validates the dataset after approval.\n",
    ">\n",
    "> Step 3: After validation, the system would be able to display the data in a dataframe.\n",
    "\n",
    "**Postconditions:** THe dataset is ready for cleaning.\n",
    "#### **Data Cleaning**\n",
    "**Actor:** Data Analyst\n",
    "\n",
    "**Goal:** To fix or remove incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset.\n",
    "\n",
    "**Preconditions:** The system already has a loaded dataset to clean.\n",
    "> Step 1: The user runs a program or software built to filter out invalid data efficiently.\n",
    ">\n",
    "> Step 2: The program or software reads the dataset. If any invalid data bis detected, they will be filtered out and removed. The user might also need to manually clean out some data at times.\n",
    ">\n",
    "> Step 3: The program or software will be able to present the cleaned dataset as a valid dataframe.\n",
    "\n",
    "**Postconditions:** The dataset has been filtered, cleaned anhd ready for the next stages of analysis.\n",
    "#### **Data Analysis**\n",
    "**Actor:** Data Analyst\n",
    "\n",
    "**Goal:** To analyse the data to extract important pieces of it and make summaries.\n",
    "\n",
    "**Preconditions:** The dataset has been thoroughly filtered and cleaned.\n",
    "> Step 1: The user runs a program or software built to analyze data efficiently.\n",
    ">\n",
    "> Step 2: The program or software reads the dataset. If any invalid data bis detected, they will be filtered out and removed. The user might also need to manually clean out some data at times.\n",
    ">\n",
    "> Step 3: The program or software will be able to present the cleaned dataset as a valid dataframe.\n",
    "\n",
    "**Postconditions:** The dataset has been filtered, cleaned anhd ready for the next stages of analysis."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
